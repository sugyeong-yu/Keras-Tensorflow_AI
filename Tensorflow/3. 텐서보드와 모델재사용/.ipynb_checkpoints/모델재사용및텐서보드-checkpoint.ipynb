{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 학습모델 저장하고 재사용하기\n",
    "- 포유류와 조류를 구분하는 신경망 모델을 이용\n",
    "- 데이터를 csv파일로 분리 뒤 해당 파일을 읽어들여 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=[[0,0],[1,0],[1,1],[0,0],[0,0],[0,1]]\n",
    "y_data=[[1,0,0],[0,1,0],[0,0,1],[1,0,0],[1,0,0],[0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습횟수를 카운트하는 변수정의 \n",
    "global_step=tf.Variable(0,trainable=False,name='global_step') #학습횟수 카운트를 위해 trainable이라는 옵션을 줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앞장에서보다 계층을 하나 늘리고\n",
    "- 편향은 없이 가중치만 사용한 모델로 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32)\n",
    "Y=tf.placeholder(tf.float32)\n",
    "\n",
    "W1=tf.Variable(tf.random_uniform([2,10],-1,1))\n",
    "L1=tf.nn.relu(tf.matmul(X,W1))\n",
    "\n",
    "W2=tf.Variable(tf.random_uniform([10,20],-1,1))\n",
    "L2=tf.nn.relu(tf.matmul(L1,W2))\n",
    "\n",
    "W3=tf.Variable(tf.random_uniform([20,3],-1,1))\n",
    "model=tf.matmul(L2,W3)\n",
    "\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y,logits=model))\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op=optimizer.minimize(cost,global_step=global_step)#모델을 최적화 할때마다 global_step의 변수의 값을 1씩 증가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "saver=tf.compat.v1.train.Saver(tf.global_variables()) # 앞서 정의한 변수들을 가져오는 함수 (이전에 학습한 결과를 불러와 저장)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 재사용\n",
    "- 기존에 학습해둔 모델이 있는지 확인 후 있다면 saver.restore함수를 이용해 학습된 값을 불러오고 아니면 변수를 새로 초기화\n",
    "- 학습한 모델을 저장한 파일 = checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt=tf.train.get_checkpoint_state('./model') # checkpoint file이 있는지 확인 > 있다면 checkpoint state, 없다면 None반환\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)#ck 파일 불러와서 변수에 할당.\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer()) # 없으면 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 cost 2.339\n",
      "step 2 cost 2.185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/dnn.ckpt-2'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#global_step은 텐서타입의 변수이므로 값을 가져올때 sess.run(global_step)을 이용해야 한다.\n",
    "for step in range(2):\n",
    "    sess.run(train_op,feed_dict={X:x_data,Y:y_data})\n",
    "    \n",
    "    print('step %d'%sess.run(global_step),\n",
    "         'cost %.3f'%sess.run(cost,feed_dict={X:x_data,Y:y_data}))\n",
    "\n",
    "# 최적화 완료 후 학습된 변수들을 지정한 chpt파일에 저장\n",
    "saver.save(sess,'./model/dnn.ckpt',global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 텐서보드 사용하기\n",
    "- 학습과정 추적을 위한 도구\n",
    "- 학습하는 중간중간 손실값, 정확도 또는 결과물로나온 이미지나 사운드파일을 다양한 방식으로 시각화 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=[[0,0],[1,0],[1,1],[0,0],[0,0],[0,1]]\n",
    "y_data=[[1,0,0],[0,1,0],[0,0,1],[1,0,0],[1,0,0],[0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습횟수를 카운트하는 변수정의 \n",
    "global_step=tf.Variable(0,trainable=False,name='global_step') #학습횟수 카운트를 위해 trainable이라는 옵션을 줌\n",
    "X=tf.placeholder(tf.float32)\n",
    "Y=tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.summary module의 scalar는 값이 하나인 텐서를 수집할때 사용\n",
    "    - histogram,image,audio등 다양한 값을 수집하는 함수를 기본으로 제공한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 신경망의 계층에 다음 코드를 덧붙여준다.\n",
    "with tf.name_scope('layer1'):\n",
    "    W1=tf.Variable(tf.random_uniform([2,10],-1,1),name='W1')\n",
    "    L1=tf.nn.relu(tf.matmul(X,W1))\n",
    "with tf.name_scope('layer2'):\n",
    "    W2=tf.Variable(tf.random_uniform([10,20],-1,1),name='W2')\n",
    "    L2=tf.nn.relu(tf.matmul(L1,W2))\n",
    "with tf.name_scope('output'):\n",
    "    W3=tf.Variable(tf.random_uniform([20,3],-1,1),name='W3')\n",
    "    model=tf.matmul(L2,W3)\n",
    "with tf.name_scope('optimizer'):\n",
    "    cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y,logits=model))\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    train_op=optimizer.minimize(cost,global_step=global_step)\n",
    "    \n",
    "    tf.summary.scalar('cost',cost) # 손실값 추적을 위해 수집할 값을 지정하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "saver=tf.compat.v1.train.Saver(tf.global_variables()) \n",
    "ckpt=tf.train.get_checkpoint_state('./model') \n",
    "\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)#ck 파일 불러와서 변수에 할당.\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer()) # 없으면 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.summary.merge_all() 로 앞서 지정한 텐서들을 수집한 다음\n",
    "- tf.summary.FileWriter로 그래프와 텐서의 값들을 저장한 디렉터리를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged=tf.summary.merge_all()\n",
    "writer=tf.summary.FileWriter('./logs',sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2 cost 1.620\n",
      "step 3 cost 1.469\n",
      "step 4 cost 1.331\n",
      "step 5 cost 1.207\n",
      "step 6 cost 1.099\n",
      "step 7 cost 1.003\n",
      "step 8 cost 0.932\n",
      "step 9 cost 0.869\n",
      "step 10 cost 0.815\n",
      "step 11 cost 0.768\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "for step in range(10):\n",
    "    sess.run(train_op,feed_dict={X:x_data,Y:y_data})\n",
    "    \n",
    "    print('step %d'%sess.run(global_step),\n",
    "         'cost %.3f'%sess.run(cost,feed_dict={X:x_data,Y:y_data}))\n",
    "    summary=sess.run(merged,feed_dict={X:x_data,Y:y_data}) # 모아둔 텐서의 값들을 계산하여 수집 (cost가 수집됨)\n",
    "    writer.add_summary(summary,global_step=sess.run(global_step)) # 해당값들을 앞서 지정한 dir에 저장, global step을 통해 수집한 시점을 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: [0 1 0 0 0 2]\n",
      "실제값: [0 1 2 0 0 2]\n",
      "정확도: 83.33\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "saver.save(sess,'./model/dnn.ckpt',global_step=global_step)\n",
    "prediction=tf.argmax(model,1)\n",
    "target=tf.argmax(Y,1)\n",
    "print('예측값:',sess.run(prediction,feed_dict={X:x_data}))\n",
    "print('실제값:',sess.run(target,feed_dict={Y:y_data}))\n",
    "\n",
    "is_correct=tf.equal(prediction,target)\n",
    "acc=tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "print('정확도: %.2f'%sess.run(acc*100,feed_dict={X:x_data,Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 해당 dir의 cmd에서 tensorboard --logdir=./logs 실행\n",
    "- http://localhost:6006 접속 시 tensorboard 웹서버 확인가능\n",
    "- scalar에는 수집한 step별 cost값이 기록되어 있고\n",
    "- graph에는 scope로 그룹핑한 결과를 볼 수 있음 > 네트워크의 구조다이어그램\n",
    "- 가중치를 보고 싶을 경우 tf.summary.histogram(\"Weights\",W1) 을 추가"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
