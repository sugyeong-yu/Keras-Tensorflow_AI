{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DQN개념\n",
    "- DQN은 Deep Q-network의 줄임말.\n",
    "- 강화학습 알고리즘으로 유명한 Q-learning을 딥러닝으로 구현했다는 말\n",
    "\n",
    "강화학습이란 어떤 환경에서 인공지능 에이전트가 현재상태(환경)을 판단하여 가장 이로운 행동을 하게 만드는 학습 방법이다.\n",
    "- 이로운행동 -> 보상을 줌\n",
    "- 해로운행동 -> 패널티를 줌\n",
    "- 즉 누적된 이득이 최대가 되게 행동하도록 학습이 진행된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q-learning\n",
    ": 어떤 상태에서 특정행동을 했을때 가치를 나타내는 함수인 Q함수를 학습하는 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 Q러닝을 신경망으로 구현하면 학습이 상당히 불안해 질 수 있다. 이는 아래 두 방법을 사용하여 해결\n",
    "1. 먼저 과거의 상태를 기억한 뒤 그중 임의의 상태를 뽑아 학습 \n",
    "    1. 이렇게하면 특수한 상황에 치우치지않도록 조절할 수 있다.\n",
    "2. 손실값을 계산하기위해 학습을 진행하면서 최적의 행동을 얻어내는 기본신경망과 얻어낸 값이 좋은 선택인지 비교하는 목표신경망을 분리하는 방법을 사용한다.\n",
    "    1. 목표신경망은 계속 갱신하는 것이 아니라 기본신경망의 학습된 결괏값을 일정주기마다 목표신경망에 갱신한다.\n",
    "   \n",
    "그리고 DQN은 화면의 상태, 즉 화면영상만으로 게임을 학습한다. 따라서 이미지 인식에 뛰어난 CNN을 사용하여 신경망 모델을 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
